##Encoder-Decoder_Case_Study

This is a case study i lead in Spring 2023 for CS7643 Deep Learning Class. In this study, we disscussed the pros and cons of fine tuning classic "deep" CNN
frameworks for a image annotation task for COCO dataset.

Abstract:
The Encoder-Decoder model is a fundamental component of machine learning that allows arbitrary input forms to be encoded into arbitrary output forms. However, the flexibility of the Encoder-Decoder model comes with extra complexity compared to traditional machine learning models, making it difficult to train. To address this difficulty in training, researchers commonly use a pre-trained encoder such as the CNN model. This paper builds an Encoder-Decoder network for Microsoft COCO image captioning using three distinct CNN networks - VGG16, Resnet101, and InceptionV3 - as encoders. The ImageNet pre-trained weights of these CNNs were fine-tuned on the Microsoft COCO dataset for a multi-label classification task. The paper compares the feature extraction quality of the pre-trained CNNs and the fine-tuned CNNs for image captioning tasks by training an LSTM decoder network on top of each CNN to generate captions. The paper also tests the initialization quality of the GloVe 6B 200 dimension embedding for all the Encoder-Decoder networks in this work. The results provide a cost and benefit analysis of utilizing pre-trained CNN or embedding for image captioning tasks. By comparing the performance of pre-trained and fine-tuned CNNs, the paper aims to determine whether the additional training time required for fine-tuning is worth the improved performance for the target task. We found that fine tuning only improve performance of VGG16 encoder configuration's image caption ability.
